{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6593b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the dataset:\n",
      "   feature_1  feature_2  target\n",
      "0          3          1       2\n",
      "1          7          9       6\n",
      "2         20         14      16\n",
      "3         13          6      12\n",
      "4          9         10       7\n",
      "Convergence reached at iteration 25074\n",
      "Theta values (including intercept):\n",
      "theta0 (Intercept): 0.10910437420417896\n",
      "theta1 (feature_1): 0.899307650991062\n",
      "theta2 (feature_2): -0.10774947322960175\n",
      "The optimized equation is: target = 0.10910437420417896 + 0.899307650991062*feature_1 + -0.10774947322960175*feature_2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to perform gradient descent for linear regression using matrix operations with tolerance\n",
    "def gradient_descent_matrix_method(X, y, learning_rate=0.0001, iterations=100000, tolerance=1e-7):\n",
    "    # Number of data points (m) and number of features (n)\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Initialize parameters (theta) to zeros (one for each feature, including intercept)\n",
    "    theta = np.zeros(n)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Compute predictions: X.dot(theta) is a matrix-vector multiplication\n",
    "        y_predicted = X.dot(theta)\n",
    "        \n",
    "        # Compute the gradient: (1/m) * X.T.dot(y_predicted - y)\n",
    "        gradient = (1/m) * X.T.dot(y_predicted - y)\n",
    "        \n",
    "        # Update parameters (theta)\n",
    "        new_theta = theta - learning_rate * gradient\n",
    "        \n",
    "        # Check for convergence: If the change in parameters is smaller than tolerance, stop\n",
    "        if np.linalg.norm(new_theta - theta, ord=1) < tolerance:\n",
    "            print(f\"Convergence reached at iteration {i}\")\n",
    "            break\n",
    "        \n",
    "        # Update theta for the next iteration\n",
    "        theta = new_theta\n",
    "    \n",
    "    # Return the final parameters (theta)\n",
    "    return theta\n",
    "\n",
    "# Function to read data from a file (CSV, Excel, JSON, etc.)\n",
    "def read_data_from_file(file_path, target_column):\n",
    "    # Get the file extension\n",
    "    file_extension = os.path.splitext(file_path)[1]\n",
    "\n",
    "    # Read the file based on the extension\n",
    "    if file_extension == '.csv':\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_extension in ['.xls', '.xlsx']:\n",
    "        df = pd.read_excel(file_path)\n",
    "    elif file_extension == '.json':\n",
    "        df = pd.read_json(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "\n",
    "    # Display the first few rows of the dataset\n",
    "    print(\"First 10 rows of the dataset:\")\n",
    "    print(df.head(10))\n",
    "\n",
    "    # Separate the target column (dependent variable, y) from the rest of the features\n",
    "    y = df[target_column].values  # Target variable (dependent)\n",
    "\n",
    "    # Drop the target column to get all features (independent variables)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "\n",
    "    # Add a column of ones for the intercept term\n",
    "    intercept_column = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept_column, X))  # Add the intercept column to the features\n",
    "\n",
    "    # Return features, target, and feature names\n",
    "    return X, y, df.drop(columns=[target_column]).columns\n",
    "\n",
    "# Main function to run the regression\n",
    "def run_regression(file_path, target_column):\n",
    "    # Step 1: Read data from the file\n",
    "    X, y, feature_names = read_data_from_file(file_path, target_column)\n",
    "\n",
    "    # Step 2: Run gradient descent with the matrix method and tolerance\n",
    "    theta = gradient_descent_matrix_method(X, y, learning_rate=0.001, tolerance=1e-7)\n",
    "\n",
    "    # Step 3: Display the theta values with names\n",
    "    print(\"Theta values (including intercept):\")\n",
    "    for i in range(len(theta)):\n",
    "        if i == 0:\n",
    "            print(f\"theta0 (Intercept): {theta[i]}\")\n",
    "        else:\n",
    "            print(f\"theta{i} ({feature_names[i-1]}): {theta[i]}\")\n",
    "\n",
    "    # Step 4: Print the optimized equation with actual feature and target names\n",
    "    equation = f\"{target_column} = {theta[0]}\"  # Start with the intercept\n",
    "    for i in range(1, len(theta)):\n",
    "        equation += f\" + {theta[i]}*{feature_names[i-1]}\"\n",
    "    \n",
    "    print(f\"The optimized equation is: {equation}\")\n",
    "\n",
    "# Example usage\n",
    "# Use the provided file path with forward slashes\n",
    "file_path = 'C:/Users/19874/OneDrive/桌面/NCSU FM/Coding Files/Machine Learning/Sample Data/Matrix GDM General.xlsx' # Copy and paste file path here, switch \\ to /\n",
    "target_column = 'target'  # Specify the name of the column that contains the dependent variable (y)\n",
    "run_regression(file_path, target_column)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
